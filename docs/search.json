[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "People’s Data",
    "section": "",
    "text": "New developments in machine learning have made it possible to consider documents and collections of documents as data, thus providing important context for the inferences drawn from those sources. But even with document or collection-level context, a fundamental principle behind critical data practices remains relevant: decisions about what becomes data (and what, in turn, does not) empower some and disempower others. We add to this principle a crucial corollary: that making connections across datasets enhances the interpretation of data by adding essential context to it.\nThis case study is centered on policy manuals from California law enforcement agencies, which can help us to rethink the design of information retrieval systems by providing an ideal ground for using the affordances of AI. State legislation requires that policy manuals be shared publicly, so as to encourage “meaningful public input” on policy, yet the documents themselves are written not to enhance public understanding of law enforcement policy but to reduce the legal liability of law enforcement. To merely make these documents available and queryable via LLMs will therefore serve to perpetuate document biases. We propose, instead, to combine Natural Language Processing tools, traditional library practices of metadata creation, and a community-based knowledge graph, in order to make them more generally comprehensible and to increase their public utility.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 1, 2024\n\n\nDeveloping a pluralist graph data structure\n\n\nCatherine Nicole Coleman\n\n\n\n\nAug 13, 2024\n\n\nExplore the Knowledge Graph\n\n\nJiaju Liu\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "knowledge-graph.html",
    "href": "knowledge-graph.html",
    "title": "Explore the Knowledge Graph",
    "section": "",
    "text": "Our People’s Data knowledge graph is integral to Wikidata. We are adding entries to build more pluralist data structures around concepts like “drone”. Select a search term to explore a concept within the context of Wikidata.\nShow the code\nviewof id = text({\n  title: 'Wikidata Unique Identifier (QID)',\n  //\n  value: (\n    new URLSearchParams(location.search).get(\"id\") || \"Q127786639\"\n  ).replace(/_/g, ' '),\n  description: \"For example, AB 481 Category 1 is Q127786639 and Rifle is Q124072. Limited to 10 ingoing and outgoing edges.\",\n  submit: \"Go\"\n})\nShow the code\n// Here is the graph visualized\n\ndot`digraph \"${id}\" {\n  outputorder=edgesfirst\n  graph[rankdir=LR, center=true]\n  node[shape=none, fontname=\"Source Serif Pro\", fontsize=13]\n  edge[arrowsize=0.6, arrowhead=vee, color=gray]\n  ${nodes}\n  ${edges}\n }`\nShow the code\nimport {queryDispatcher} from \"@lukesmurray/wikidata-sparql-helpers\"\n\nquery = `SELECT ?parent ?parentLabel ?count\nWHERE\n{\n  {\n    SELECT ?parent (COUNT(?child) AS ?count)\n    WHERE\n    {\n      ?parent wdt:P40 ?child.\n    }\n    GROUP BY ?parent\n    ORDER BY DESC(?count)\n    LIMIT 10\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nORDER BY DESC(?count)\nLIMIT 10`\n\n\nnodes = picturein.map(i =&gt; `\"${wrapText(i.valueLabel)}\" [URL=\"?id=${i.value.split(\"/\")[i.value.split(\"/\").length-1]}\", fontcolor=\"#3182bd\", target=\"_top\"]`).concat(pictureout.map(i =&gt; `\"${wrapText(i.valueLabel)}\" [URL=\"?id=${i.value.split(\"/\")[i.value.split(\"/\").length-1]}\", fontcolor=\"#3182bd\", target=\"_top\"]`)).join(\"\\n\")\n\nedges = Array.from(new Set(picturein.map(i =&gt; `\"${wrapText(i.valueLabel)}\" -&gt; \"${wrapText(i.itemLabel)}\" [label=\"${wrapText(i.edgeLabel)}\"]`).concat(pictureout.map(i =&gt; `\"${wrapText(i.itemLabel)}\" -&gt; \"${wrapText(i.valueLabel)}\" [label=\"${wrapText(i.edgeLabel)}\"]`)))).join(\"\\n\")\n\n\ngraphqueryout = `SELECT ?item ?itemLabel ?itemImage ?value ?valueLabel ?valueImage ?edgeLabel WHERE {\n  {BIND(wd:${id} AS ?item)\n  ?item ?wdt ?value.\n  ?edge a wikibase:Property;\n        wikibase:propertyType wikibase:WikibaseItem; # note: to show all statements, removing this is not enough, the graph view only shows entities\n        wikibase:directClaim ?wdt.\n  OPTIONAL { ?item wdt:P18 ?itemImage. }\n  OPTIONAL { ?value wdt:P18 ?valueImage. }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}}\n}\nLIMIT 10`\n\ngraphqueryin = `SELECT ?item ?itemLabel ?itemImage ?value ?valueLabel ?valueImage ?edgeLabel WHERE {\n  {BIND(wd:${id} AS ?item)\n  ?value ?wdt ?item.\n  ?edge a wikibase:Property;\n        wikibase:propertyType wikibase:WikibaseItem; # note: to show all statements, removing this is not enough, the graph view only shows entities\n        wikibase:directClaim ?wdt.\n  OPTIONAL { ?item wdt:P18 ?itemImage. }\n  OPTIONAL { ?value wdt:P18 ?valueImage. }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}}\n}\nLIMIT 10`\n\npictureout = queryDispatcher.query(graphqueryout)\n\npicturein = queryDispatcher.query(graphqueryin)\n\npicturein.map(i =&gt; `\"${wrapText(i.itemLabel)}\" -&gt; \"${wrapText(i.valueLabel)}\"`).join(\"\\n\")\nShow the code\nlexer = text =&gt; text.split(/[_ ]/g)\nShow the code\nimport {text} from \"@jashkenas/inputs\"\nShow the code\nwrapText = (text, len = 15) =&gt; {\n  const words = lexer(text);\n  let lines = '';\n  let count = 0;\n  for (let word of words) {\n    if (count + word.length &gt;= len) {\n      lines += `\\n${word} `;\n      count = word.length;\n    } else {\n      lines += `${word} `;\n      count += word.length;\n    }\n  }\n  return lines.trim();\n}"
  },
  {
    "objectID": "knowledge-graph.html#references",
    "href": "knowledge-graph.html#references",
    "title": "Explore the Knowledge Graph",
    "section": "References:",
    "text": "References:\n\n\nShow the code\n{\n  const refs = [\n    '@mbostock/working-with-wikipedia-data',\n    '@mbostock/graphviz',\n    '@observablehq/how-observable-runs',\n    '@observablehq/notebook-visualizer',\n    '@chriszs/wikipedia-concept-graph'\n  ];\n\n  return md`refs: ${refs.map(d =&gt; `[${d}](/${d})`).join(', ')}`;\n}"
  },
  {
    "objectID": "schema.html",
    "href": "schema.html",
    "title": "Developing a pluralist graph data structure",
    "section": "",
    "text": "Stanford University\n    \n  \n\n\n\n\nData structures help us to find information within an otherwise undifferentiated swamp. But data structures are not neutral. They involve decision-making and they are constrained by those decisions. [put here text about why wikidata]\n\nWorking within the constraints of Wikidata\nWhile Wikipedia allows for long narrative description of concepts, Wikidata is designed as a graph structure of nodes and links between nodes that can be explored quickly and easiy. Deriving properties from descriptions is a reductive process; important information and context is lost. To build a pluralist data structure, we sought a method for arriving at concise properties and values from long descriptions.\nFor military equipment, ‘description’ can mean something very different depending on the source. They can range from functional categorization to marketing rhetoric meant to pursuade and entice buyers. That makes it difficult to draw comparisons. The approach outlined below takes us from rich description to properties that are more easily understood in relation to each other and their context. Businesses focus on technological\n\n\nFrom a single description to multiple perspectives\nThe most visible and available descriptions of military equipment come from the businesses that market the equipment for sale. We gather additional descriptions from these other sources: legal (government legislation), enforcement (police and other government agencies), civic (organizations and community groups), and individual (direct personal experience).\n\n\n\n\n\n\n\n\n\n\nbusiness\nLegal\nenforcement\ncivic\nindividual\n\n\n\n\nmultiple\none to many\nmultiple\nmultiple\nmultiple\n\n\ncapabilities\ncategory\nuse\neffects\nexperience\n\n\n\n\n\nMultiple perspectives to arrive at properties for the concept “drone”\nWhen we began this project, most drone entries in Wikidata were for specific models made by manufacturers. We connect those different models to a general class, “Miniature Unmanned Aerial Vehicle” (alias “drone”). We then connect “drone” to California legislation AB481 Category 1 of which drone is a subclass. We connect California law enforcement agencies that use drones both to the class “drone” and to the specific model of drone when we have that information.\n\n\n\n\n\n\n\nschema\n\n\n\ndrone\n\ndrone\n\n\n\nLEGAL\n\nLEGAL\n\n\n\nLEGAL-&gt;drone\n\n\nCat 1\n\n\n\nrobot\n\nrobot\n\n\n\nLEGAL-&gt;robot\n\n\nCat 1\n\n\n\nBUSINESS\n\nBUSINESS\n\n\n\nBUSINESS-&gt;drone\n\n\nheat sensitive\n\n\n\nBUSINESS-&gt;drone\n\n\nhigh-res camera\n\n\n\nENFORCEMENT\n\nENFORCEMENT\n\n\n\nENFORCEMENT-&gt;drone\n\n\nsurveillance\n\n\n\nENFORCEMENT-&gt;drone\n\n\ncommunication\n\n\n\nINDIVIDUAL\n\nINDIVIDUAL\n\n\n\nINDIVIDUAL-&gt;drone\n\n\nchilling\n\n\n\nINDIVIDUAL-&gt;drone\n\n\nintimidating\n\n\n\nCIVIC\n\nCIVIC\n\n\n\nCIVIC-&gt;drone\n\n\nprivacy\n\n\n\nCIVIC-&gt;drone\n\n\nmental health"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is where we share work in progress for the project, People’s Data. The purpose of this project is to design an open system of data creation and use that is pluralist, interconnected, and changing. The core elements of the project are: a knowledge graph for flexibility in the data structure, machine learning to aid information discovery, community involvement to guide use and effectiveness of the system, and data curation that assumes that all perspectives are partial while making space for multiplicity and contestation.\nThis project is supported by CESTA, the Center for Spatial and Textual Analysis at Stanford University. This work builds on a previous (2023) CESTA-supported project, Know More Names, which, in turn was rooted in the Know Systemic Racism initiative led by Felicia Smith, the Racial Justice and Social Equity Librarian at Stanford Libraries."
  },
  {
    "objectID": "about.html#summer-2024-project-team",
    "href": "about.html#summer-2024-project-team",
    "title": "About",
    "section": "Summer 2024 Project Team",
    "text": "Summer 2024 Project Team\nJiaju Liu, CESTA Undergraduate Intern, Stanford University, class of 2025.\nJorge Gonzalez, OCE Undergraduate Intern, College of San Mateo.\nCatherine Nicole Coleman, Project Lead, Digital Research Architect, Stanford Libraries."
  },
  {
    "objectID": "knowledge-graph copy.html",
    "href": "knowledge-graph copy.html",
    "title": "Explore the Knowledge Graph",
    "section": "",
    "text": "Stanford University\nOur People’s Data knowledge graph is integral to Wikidata. We are adding entries to build more pluralist data structures around concepts like “drone”. Select a search term to explore a concept within the context of Wikidata.\nviewof id = text({\n  title: 'Wikidata Unique Identifier (QID)',\n  //\n  value: (\n    new URLSearchParams(location.search).get(\"id\") || \"Q127786639\"\n  ).replace(/_/g, ' '),\n  description: \"For example, AB 481 Category 1 is Q127786639 and Rifle is Q124072. Limited to 10 ingoing and outgoing edges.\",\n  submit: \"Go\"\n})\n// Here is the graph visualized\n\ndot`digraph \"${id}\" {\n  outputorder=edgesfirst\n  graph[rankdir=LR, center=true]\n  node[shape=none, fontname=\"Source Serif Pro\", fontsize=13]\n  edge[arrowsize=0.6, arrowhead=vee, color=gray]\n  ${nodes}\n  ${edges}\n }`\nimport {queryDispatcher} from \"@lukesmurray/wikidata-sparql-helpers\"\n\nquery = `SELECT ?parent ?parentLabel ?count\nWHERE\n{\n  {\n    SELECT ?parent (COUNT(?child) AS ?count)\n    WHERE\n    {\n      ?parent wdt:P40 ?child.\n    }\n    GROUP BY ?parent\n    ORDER BY DESC(?count)\n    LIMIT 10\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nORDER BY DESC(?count)\nLIMIT 10`\n\n\nnodes = picturein.map(i =&gt; `\"${wrapText(i.valueLabel)}\" [URL=\"?id=${i.value.split(\"/\")[i.value.split(\"/\").length-1]}\", fontcolor=\"#3182bd\", target=\"_top\"]`).concat(pictureout.map(i =&gt; `\"${wrapText(i.valueLabel)}\" [URL=\"?id=${i.value.split(\"/\")[i.value.split(\"/\").length-1]}\", fontcolor=\"#3182bd\", target=\"_top\"]`)).join(\"\\n\")\n\nedges = Array.from(new Set(picturein.map(i =&gt; `\"${wrapText(i.valueLabel)}\" -&gt; \"${wrapText(i.itemLabel)}\" [label=\"${wrapText(i.edgeLabel)}\"]`).concat(pictureout.map(i =&gt; `\"${wrapText(i.itemLabel)}\" -&gt; \"${wrapText(i.valueLabel)}\" [label=\"${wrapText(i.edgeLabel)}\"]`)))).join(\"\\n\")\n\n\ngraphqueryout = `SELECT ?item ?itemLabel ?itemImage ?value ?valueLabel ?valueImage ?edgeLabel WHERE {\n  {BIND(wd:${id} AS ?item)\n  ?item ?wdt ?value.\n  ?edge a wikibase:Property;\n        wikibase:propertyType wikibase:WikibaseItem; # note: to show all statements, removing this is not enough, the graph view only shows entities\n        wikibase:directClaim ?wdt.\n  OPTIONAL { ?item wdt:P18 ?itemImage. }\n  OPTIONAL { ?value wdt:P18 ?valueImage. }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}}\n}\nLIMIT 10`\n\ngraphqueryin = `SELECT ?item ?itemLabel ?itemImage ?value ?valueLabel ?valueImage ?edgeLabel WHERE {\n  {BIND(wd:${id} AS ?item)\n  ?value ?wdt ?item.\n  ?edge a wikibase:Property;\n        wikibase:propertyType wikibase:WikibaseItem; # note: to show all statements, removing this is not enough, the graph view only shows entities\n        wikibase:directClaim ?wdt.\n  OPTIONAL { ?item wdt:P18 ?itemImage. }\n  OPTIONAL { ?value wdt:P18 ?valueImage. }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}}\n}\nLIMIT 10`\n\npictureout = queryDispatcher.query(graphqueryout)\n\npicturein = queryDispatcher.query(graphqueryin)\n\npicturein.map(i =&gt; `\"${wrapText(i.itemLabel)}\" -&gt; \"${wrapText(i.valueLabel)}\"`).join(\"\\n\")\nlexer = text =&gt; text.split(/[_ ]/g)\nimport {text} from \"@jashkenas/inputs\"\nwrapText = (text, len = 15) =&gt; {\n  const words = lexer(text);\n  let lines = '';\n  let count = 0;\n  for (let word of words) {\n    if (count + word.length &gt;= len) {\n      lines += `\\n${word} `;\n      count = word.length;\n    } else {\n      lines += `${word} `;\n      count += word.length;\n    }\n  }\n  return lines.trim();\n}"
  },
  {
    "objectID": "knowledge-graph copy.html#references",
    "href": "knowledge-graph copy.html#references",
    "title": "Explore the Knowledge Graph",
    "section": "References:",
    "text": "References:\n\n{\n  const refs = [\n    '@mbostock/working-with-wikipedia-data',\n    '@mbostock/graphviz',\n    '@observablehq/how-observable-runs',\n    '@observablehq/notebook-visualizer',\n    '@chriszs/wikipedia-concept-graph'\n  ];\n\n  return md`refs: ${refs.map(d =&gt; `[${d}](/${d})`).join(', ')}`;\n}"
  }
]